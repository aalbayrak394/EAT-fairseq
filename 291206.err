/mnt/stud/home/aalbayrak/DLL/EAT-fairseq/fairseq_cli/hydra_train.py:25: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path=os.path.join("..", "fairseq", "config"), config_name="config")
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=hydra_train
/mnt/stud/home/aalbayrak/.conda/envs/birdset/lib/python3.10/site-packages/hydra/core/default_element.py:124: UserWarning: In 'pretraining_BirdSet': Usage of deprecated keyword in package header '# @package _group_'.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information
  deprecation_warning(
sys:1: UserWarning: 
'pretraining_BirdSet' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
/mnt/stud/home/aalbayrak/.conda/envs/birdset/lib/python3.10/site-packages/hydra/main.py:90: UserWarning: 
'pretraining_BirdSet' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  _run_hydra(
/mnt/stud/home/aalbayrak/.conda/envs/birdset/lib/python3.10/site-packages/hydra/_internal/utils.py:465: UserWarning: 
'pretraining_BirdSet' is validated against ConfigStore schema with the same name.
This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.
See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.
  run_and_report(
/mnt/stud/home/aalbayrak/.conda/envs/birdset/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_launcher.py:74: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
wandb: Currently logged in as: aalbayrak (DLL-EAT). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /mnt/stud/home/aalbayrak/DLL/EAT-fairseq/multirun/2024-08-10/10-18-20/0/wandb/run-20240810_101840-rkvjhrcf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-dawn-1
wandb: â­ï¸ View project at https://wandb.ai/DLL-EAT/Pretraining-BirdSet
wandb: ğŸš€ View run at https://wandb.ai/DLL-EAT/Pretraining-BirdSet/runs/rkvjhrcf
wandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: / 0.027 MB of 0.027 MB uploadedwandb: - 0.101 MB of 1.438 MB uploadedwandb: \ 1.445 MB of 1.445 MB uploadedwandb: | 1.445 MB of 1.445 MB uploadedwandb: 
wandb: Run history:
wandb:                                       train/bsz â–â–â–â–
wandb:                                      train/clip â–‡â–â–†â–ˆ
wandb:                                 train/ema_decay â–â–ˆâ–ˆâ–ˆ
wandb:                                   train/gb_free â–â–â–â–
wandb:                                     train/gnorm â–ˆâ–â–â–
wandb:                                      train/loss â–ˆâ–â–â–
wandb:                     train/loss_IMAGE_regression â–ˆâ–â–ƒâ–„
wandb:                                  train/loss_cls â–ˆâ–â–â–
wandb:                                train/loss_scale â–â–ƒâ–ƒâ–ˆ
wandb:       train/lr_c34292026c238657737ef782d45f6878 â–ˆâ–„â–â–‚
wandb:                                train/lr_default â–ˆâ–„â–â–‚
wandb:                                train/masked_pct â–â–â–â–
wandb:                                train/nsentences â–â–â–â–
wandb:                                   train/ntokens â–â–â–â–
wandb:                                  train/pred_var â–ˆâ–…â–‚â–
wandb:                               train/sample_size â–â–â–â–
wandb:                                train/target_var â–ˆâ–ƒâ–â–
wandb:                                train/train_wall â–ˆâ–ˆâ–ˆâ–
wandb:                                       train/ups â–â–…â–‚â–ˆ
wandb:                                      train/wall â–â–„â–ˆâ–ˆ
wandb:                                       train/wpb â–â–â–â–
wandb:                                       train/wps â–â–…â–‚â–ˆ
wandb:                                 train_inner/bsz â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                                train_inner/clip â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–‡â–ƒâ–ˆâ–†â–‡â–â–‡â–…â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                           train_inner/ema_decay â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                             train_inner/gb_free â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                               train_inner/gnorm â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                                train_inner/loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:               train_inner/loss_IMAGE_regression â–†â–â–ƒâ–†â–ˆâ–ˆâ–…â–ƒâ–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:                            train_inner/loss_cls â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train_inner/loss_scale â–â–â–â–â–‚â–„â–„â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–„â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–„â–ˆâ–â–â–â–‚â–‚
wandb: train_inner/lr_c34292026c238657737ef782d45f6878 â–â–ƒâ–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:                          train_inner/lr_default â–â–ƒâ–„â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:                          train_inner/masked_pct â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train_inner/nsentences â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                             train_inner/ntokens â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                            train_inner/pred_var â–ƒâ–ˆâ–‡â–„â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         train_inner/sample_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train_inner/target_var â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          train_inner/train_wall â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–†â–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–ƒâ–ƒâ–ƒ
wandb:                                 train_inner/ups â–ƒâ–„â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                train_inner/wall â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                                 train_inner/wpb â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                                 train_inner/wps â–ƒâ–„â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:                                       train/bsz 12.0
wandb:                                      train/clip 100.0
wandb:                                 train/ema_decay 999.99
wandb:                                   train/gb_free 25.4
wandb:                                     train/gnorm 6.903
wandb:                                      train/loss 6.251
wandb:                     train/loss_IMAGE_regression 5.027
wandb:                                  train/loss_cls 1.223
wandb:                                train/loss_scale 0.0156
wandb:       train/lr_c34292026c238657737ef782d45f6878 5e-05
wandb:                                train/lr_default 5e-05
wandb:                                train/masked_pct 0.801
wandb:                                train/nsentences 12.0
wandb:                                   train/ntokens 78720.0
wandb:                                  train/pred_var 0.839
wandb:                               train/sample_size 78720.0
wandb:                                train/target_var 0.925
wandb:                                train/train_wall 4429.0
wandb:                                       train/ups 3.93
wandb:                                      train/wall 128297.0
wandb:                                       train/wpb 78720.0
wandb:                                       train/wps 309149.1
wandb:                                 train_inner/bsz 12.0
wandb:                                train_inner/clip 100.0
wandb:                           train_inner/ema_decay 999.99
wandb:                             train_inner/gb_free 25.4
wandb:                               train_inner/gnorm 7.032
wandb:                                train_inner/loss 6.294
wandb:               train_inner/loss_IMAGE_regression 5.038
wandb:                            train_inner/loss_cls 1.256
wandb:                          train_inner/loss_scale 0.0156
wandb: train_inner/lr_c34292026c238657737ef782d45f6878 5e-05
wandb:                          train_inner/lr_default 5e-05
wandb:                          train_inner/masked_pct 0.801
wandb:                          train_inner/nsentences 12.0
wandb:                             train_inner/ntokens 78720.0
wandb:                            train_inner/pred_var 0.839
wandb:                         train_inner/sample_size 78720.0
wandb:                          train_inner/target_var 0.926
wandb:                          train_inner/train_wall 49.0
wandb:                                 train_inner/ups 4.04
wandb:                                train_inner/wall 128271.0
wandb:                                 train_inner/wpb 78720.0
wandb:                                 train_inner/wps 318386.7
wandb: 
wandb: ğŸš€ View run snowy-dawn-1 at: https://wandb.ai/DLL-EAT/Pretraining-BirdSet/runs/rkvjhrcf
wandb: â­ï¸ View project at: https://wandb.ai/DLL-EAT/Pretraining-BirdSet
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_101840-rkvjhrcf/logs
